\par Comme nous allons paralléliser un code séquentiel existant,
nous sommes dépendant du langage de ce code. Le code source fourni 
étant du C, naturellement nous nous dirigerons vers une solution 
de parallélisation MPI, que nous avons eu l'occasion de prendre 
en main dans le cadre de ce module. Cependant, reste le choix de la 
version MPI que nous utiliserons.\\
\par La version 1.3 nous fournissait une API permettant d'abstraire 
l'architecture des noeuds et de communiquer avec eux facilement. C'est
celle que nous avons utilisé durant les travaux pratiques.\\
\par La version 2.x effectue les mêmes opérations que la version 1.3,
sauf qu'on plus il nous permet de gérer un pool de threads et d'effectuer des communications unilatérales.\\
\par Afin de paralléliser le code sur chaque noeud en utilisant des threads,
deux choix s'offrent à nous : utiliser l'API POSIX ou l'API OpenMP.\\
La première est complètement gérée à partir de MPI-2.x mais nous serons sans doute
obligé d'utiliser des verrous pour l'accès aux données partagées par les threads.
Alors que la seconde nous abstrait de ce genre de considérations, en permettant 
des déclarations de variables privées, visibles uniquement pour le thread dans lequel elle est déclarée, ou publique visible pour tout les threads.\\

\par Nous utiliserons donc l'API OpenMP.\\

\par Le $"cluster$" que nous utiliserons pour effectuer nos tests 
est homogène, chaque machine a les mêmes processeurs, la même 
quantité de mémoire, et les temps de communications seront sensiblement 
les mêmes entre chaque noeud. De plus, comme nous comptons recouvrir les temps de communications par le calcul et que nous allons utiliser l'API OpenMP pour créer des threads, nous n'utiliserons pas les nouvelles fonctionnalités offertes
par MPI-2.x. Nous utiliserons donc la version 1.3 de MPI.\\